{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"f:\\\\zizo\\\\MLOPS\\\\datascienceproject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\zizo\\\\MLOPS\\\\datascienceproject'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_name: str\n",
    "    sequence_length: int\n",
    "    optimizer: str\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "    patience: int\n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.constants import *\n",
    "from src.datascience.utils.common import read_yaml,create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        self.schema=read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.LSTM\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model_name = config.model_name,\n",
    "            sequence_length=params.sequence_length,\n",
    "            optimizer = params.optimizer,\n",
    "            learning_rate= params.learning_rate,\n",
    "            batch_size = params.batch_size,\n",
    "            epochs = params.epochs,\n",
    "            patience = params.patience,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "        \n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from src.datascience import logger\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "    def create_sequence_and_training(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        df = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "        sequence_length = self.config.sequence_length\n",
    "        num_features = len(df.columns)\n",
    "\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        for i in range(len(scaled_data) - sequence_length):\n",
    "            seq = scaled_data[i:i+sequence_length]\n",
    "            label = scaled_data[i+sequence_length][3]\n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "\n",
    "        sequences = np.array(sequences)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        train_size = int(0.8 * len(sequences))\n",
    "        train_x, test_x = sequences[:train_size], sequences[train_size:]\n",
    "        train_y, test_y = labels[:train_size], labels[train_size:]\n",
    "\n",
    "        print(\"Train X shape:\", train_x.shape)\n",
    "        print(\"Train Y shape:\", train_y.shape)\n",
    "        print(\"Test X shape:\", test_x.shape)\n",
    "        print(\"Test Y shape:\", test_y.shape)\n",
    "        return train_x,train_y\n",
    "\n",
    "    def Creating_model(self,train_x,train_y):\n",
    "        model = Sequential([\n",
    "            Input(shape=(train_x.shape[1], train_x.shape[2])),\n",
    "            LSTM(units=128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(units=64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(units=32, return_sequences=False),\n",
    "            Dropout(0.2),\n",
    "            Dense(units=1)\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=self.config.optimizer, loss='mean_squared_error')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=self.config.patience, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(os.path.join(self.config.root_dir, self.config.model_name), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_x, train_y,\n",
    "            epochs=self.config.epochs,\n",
    "            batch_size=self.config.batch_size,\n",
    "            validation_split=0.2,  # Use part of the training data as validation\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-15 15:04:18,945: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-04-15 15:04:18,946: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-04-15 15:04:18,949: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-04-15 15:04:18,949: INFO: common: created directory at: artifacts]\n",
      "[2025-04-15 15:04:18,950: INFO: common: created directory at: artifacts/model_trainer]\n",
      "Train X shape: (78748, 10, 9)\n",
      "Train Y shape: (78748,)\n",
      "Test X shape: (19688, 10, 9)\n",
      "Test Y shape: (19688,)\n",
      "Epoch 1/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - loss: 0.0147 - val_loss: 0.0041\n",
      "Epoch 2/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 3/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 4/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 5/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 6/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 7/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 8/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 9/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 10/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 11/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 12/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 13/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 14/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 15/15\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config = model_trainer_config)\n",
    "    train_x ,train_y = model_trainer_config.create_sequence_and_training()\n",
    "    model_trainer_config.Creating_model(train_x,train_y)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
